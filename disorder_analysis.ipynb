{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "from collections import Counter\n",
    "from utils_corrected import process_GO_data, evaluate_annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_for_fdr_level(predicted_terms_pkl, test_entries, target_fdr):\n",
    "    \"\"\"Get predictions at specific FDR level\"\"\"\n",
    "    if target_fdr in predicted_terms_pkl:\n",
    "        predictions_list = predicted_terms_pkl[target_fdr]\n",
    "        return {\n",
    "            test_entries[i]: set(pred_tuple) \n",
    "            for i, pred_tuple in enumerate(predictions_list) \n",
    "            if pred_tuple  # Only if there are predictions\n",
    "        }\n",
    "    else:\n",
    "        print(f\"Warning: FDR {target_fdr} not found in predictions\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading Test Data ===\n",
      "Loaded 26746 test entries\n",
      "=== Loading Predictions ===\n",
      "Available FDR levels: [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]...\n",
      "Number of entries per FDR level: 26746\n",
      "Entry count matches predictions\n",
      "Disorder rate bins: [Interval(0.0, 0.1, closed='left'), Interval(0.1, 0.2, closed='left'), Interval(0.2, 0.3, closed='left'), Interval(0.3, 0.4, closed='left'), Interval(0.4, 0.5, closed='left'), Interval(0.5, 0.6, closed='left'), Interval(0.6, 0.7, closed='left'), Interval(0.7, 0.8, closed='left'), Interval(0.8, 0.9, closed='left'), Interval(0.9, 1.0, closed='left')]\n",
      "Entries per bin: [('[0.0, 0.1)', 12901), ('[0.1, 0.2)', 4731), ('[0.2, 0.3)', 3083), ('[0.3, 0.4)', 2080), ('[0.4, 0.5)', 1463), ('[0.5, 0.6)', 993), ('[0.6, 0.7)', 569), ('[0.7, 0.8)', 345), ('[0.8, 0.9)', 202), ('[0.9, 1.0)', 178)]\n",
      "=== Starting Analysis ===\n",
      "\n",
      "Processing bin interval: [0.0, 0.1)\n",
      "  Entries in bin: 12901\n",
      "  Entries with ground truth: 12901\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 12901\n",
      "      F1: 0.740, Precision: 0.992, Recall: 0.590, Micro F1: 0.655, Smin 6.700218437808007\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 12901\n",
      "      F1: 0.837, Precision: 0.958, Recall: 0.744, Micro F1: 0.787, Smin 4.6945701373309605\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 12901\n",
      "      F1: 0.864, Precision: 0.921, Recall: 0.813, Micro F1: 0.830, Smin 3.7187880724367752\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 12901\n",
      "      F1: 0.864, Precision: 0.857, Recall: 0.870, Micro F1: 0.839, Smin 3.127427175446766\n",
      "\n",
      "Processing bin interval: [0.1, 0.2)\n",
      "  Entries in bin: 4731\n",
      "  Entries with ground truth: 4730\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 4730\n",
      "      F1: 0.717, Precision: 0.990, Recall: 0.562, Micro F1: 0.641, Smin 6.553651485649636\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 4730\n",
      "      F1: 0.821, Precision: 0.951, Recall: 0.722, Micro F1: 0.779, Smin 4.487694295484331\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 4730\n",
      "      F1: 0.853, Precision: 0.916, Recall: 0.798, Micro F1: 0.825, Smin 3.549931395183242\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 4730\n",
      "      F1: 0.855, Precision: 0.850, Recall: 0.860, Micro F1: 0.833, Smin 2.9562511893522974\n",
      "\n",
      "Processing bin interval: [0.2, 0.3)\n",
      "  Entries in bin: 3083\n",
      "  Entries with ground truth: 3083\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 3083\n",
      "      F1: 0.700, Precision: 0.988, Recall: 0.543, Micro F1: 0.636, Smin 6.781069979435632\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 3083\n",
      "      F1: 0.812, Precision: 0.948, Recall: 0.710, Micro F1: 0.779, Smin 4.691415546067393\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 3083\n",
      "      F1: 0.842, Precision: 0.913, Recall: 0.782, Micro F1: 0.821, Smin 3.7680601337676185\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 3083\n",
      "      F1: 0.850, Precision: 0.850, Recall: 0.849, Micro F1: 0.833, Smin 3.0203880434433996\n",
      "\n",
      "Processing bin interval: [0.3, 0.4)\n",
      "  Entries in bin: 2080\n",
      "  Entries with ground truth: 2080\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 2080\n",
      "      F1: 0.687, Precision: 0.990, Recall: 0.526, Micro F1: 0.614, Smin 6.754017427457547\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 2080\n",
      "      F1: 0.801, Precision: 0.940, Recall: 0.698, Micro F1: 0.763, Smin 4.685396170133711\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 2080\n",
      "      F1: 0.834, Precision: 0.903, Recall: 0.774, Micro F1: 0.808, Smin 3.833877886097024\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 2080\n",
      "      F1: 0.840, Precision: 0.833, Recall: 0.847, Micro F1: 0.822, Smin 3.1236394090015156\n",
      "\n",
      "Processing bin interval: [0.4, 0.5)\n",
      "  Entries in bin: 1463\n",
      "  Entries with ground truth: 1463\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 1463\n",
      "      F1: 0.705, Precision: 0.991, Recall: 0.548, Micro F1: 0.632, Smin 6.255885708490209\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 1463\n",
      "      F1: 0.809, Precision: 0.946, Recall: 0.706, Micro F1: 0.762, Smin 4.476658003816928\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 1463\n",
      "      F1: 0.834, Precision: 0.903, Recall: 0.775, Micro F1: 0.802, Smin 3.7268761110893376\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 1463\n",
      "      F1: 0.836, Precision: 0.826, Recall: 0.847, Micro F1: 0.813, Smin 3.116113651512602\n",
      "\n",
      "Processing bin interval: [0.5, 0.6)\n",
      "  Entries in bin: 993\n",
      "  Entries with ground truth: 993\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 993\n",
      "      F1: 0.688, Precision: 0.990, Recall: 0.527, Micro F1: 0.606, Smin 6.671741887394623\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 993\n",
      "      F1: 0.801, Precision: 0.939, Recall: 0.699, Micro F1: 0.752, Smin 4.786812457940262\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 993\n",
      "      F1: 0.829, Precision: 0.888, Recall: 0.777, Micro F1: 0.795, Smin 3.925272368666693\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 993\n",
      "      F1: 0.836, Precision: 0.818, Recall: 0.855, Micro F1: 0.810, Smin 3.3222172558434\n",
      "\n",
      "Processing bin interval: [0.6, 0.7)\n",
      "  Entries in bin: 569\n",
      "  Entries with ground truth: 569\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 569\n",
      "      F1: 0.662, Precision: 0.990, Recall: 0.497, Micro F1: 0.580, Smin 8.003616367222143\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 569\n",
      "      F1: 0.774, Precision: 0.922, Recall: 0.668, Micro F1: 0.736, Smin 5.657042577328756\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 569\n",
      "      F1: 0.809, Precision: 0.877, Recall: 0.750, Micro F1: 0.781, Smin 4.725952368919518\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 569\n",
      "      F1: 0.816, Precision: 0.798, Recall: 0.836, Micro F1: 0.791, Smin 4.143582347677641\n",
      "\n",
      "Processing bin interval: [0.7, 0.8)\n",
      "  Entries in bin: 345\n",
      "  Entries with ground truth: 345\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 345\n",
      "      F1: 0.612, Precision: 0.995, Recall: 0.442, Micro F1: 0.545, Smin 8.473916060166745\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 345\n",
      "      F1: 0.757, Precision: 0.936, Recall: 0.635, Micro F1: 0.716, Smin 6.112482830028474\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 345\n",
      "      F1: 0.807, Precision: 0.886, Recall: 0.741, Micro F1: 0.783, Smin 4.98931525162638\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 345\n",
      "      F1: 0.832, Precision: 0.814, Recall: 0.850, Micro F1: 0.807, Smin 4.059179745542377\n",
      "\n",
      "Processing bin interval: [0.8, 0.9)\n",
      "  Entries in bin: 202\n",
      "  Entries with ground truth: 202\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 202\n",
      "      F1: 0.607, Precision: 0.996, Recall: 0.436, Micro F1: 0.528, Smin 9.401533100268683\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 202\n",
      "      F1: 0.748, Precision: 0.939, Recall: 0.621, Micro F1: 0.696, Smin 7.231265873830791\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 202\n",
      "      F1: 0.795, Precision: 0.898, Recall: 0.713, Micro F1: 0.770, Smin 5.973706740941025\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 202\n",
      "      F1: 0.809, Precision: 0.798, Recall: 0.820, Micro F1: 0.800, Smin 4.570500067707234\n",
      "\n",
      "Processing bin interval: [0.9, 1.0)\n",
      "  Entries in bin: 178\n",
      "  Entries with ground truth: 178\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 178\n",
      "      F1: 0.648, Precision: 0.989, Recall: 0.482, Micro F1: 0.562, Smin 7.357662032243189\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 178\n",
      "      F1: 0.798, Precision: 0.958, Recall: 0.684, Micro F1: 0.741, Smin 5.577267124305756\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 178\n",
      "      F1: 0.812, Precision: 0.893, Recall: 0.744, Micro F1: 0.781, Smin 4.926026480815575\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 178\n",
      "      F1: 0.825, Precision: 0.798, Recall: 0.854, Micro F1: 0.804, Smin 3.661847745926353\n",
      "\n",
      "=== Analysis Complete ===\n",
      "\n",
      "--- Summary of Disorder Rate Intervals and Target FDR Metrics ---\n",
      "   disorder_interval  target_FDR     F1  Precision  Recall  Micro_F1  \\\n",
      "0          [0.0-0.1)        0.01  0.740      0.992   0.590     0.655   \n",
      "1          [0.0-0.1)        0.05  0.837      0.958   0.744     0.787   \n",
      "2          [0.0-0.1)        0.10  0.864      0.921   0.813     0.830   \n",
      "3          [0.0-0.1)        0.20  0.864      0.857   0.870     0.839   \n",
      "4          [0.1-0.2)        0.01  0.717      0.990   0.562     0.641   \n",
      "5          [0.1-0.2)        0.05  0.821      0.951   0.722     0.779   \n",
      "6          [0.1-0.2)        0.10  0.853      0.916   0.798     0.825   \n",
      "7          [0.1-0.2)        0.20  0.855      0.850   0.860     0.833   \n",
      "8          [0.2-0.3)        0.01  0.700      0.988   0.543     0.636   \n",
      "9          [0.2-0.3)        0.05  0.812      0.948   0.710     0.779   \n",
      "10         [0.2-0.3)        0.10  0.842      0.913   0.782     0.821   \n",
      "11         [0.2-0.3)        0.20  0.850      0.850   0.849     0.833   \n",
      "12         [0.3-0.4)        0.01  0.687      0.990   0.526     0.614   \n",
      "13         [0.3-0.4)        0.05  0.801      0.940   0.698     0.763   \n",
      "14         [0.3-0.4)        0.10  0.834      0.903   0.774     0.808   \n",
      "15         [0.3-0.4)        0.20  0.840      0.833   0.847     0.822   \n",
      "16         [0.4-0.5)        0.01  0.705      0.991   0.548     0.632   \n",
      "17         [0.4-0.5)        0.05  0.809      0.946   0.706     0.762   \n",
      "18         [0.4-0.5)        0.10  0.834      0.903   0.775     0.802   \n",
      "19         [0.4-0.5)        0.20  0.836      0.826   0.847     0.813   \n",
      "20         [0.5-0.6)        0.01  0.688      0.990   0.527     0.606   \n",
      "21         [0.5-0.6)        0.05  0.801      0.939   0.699     0.752   \n",
      "22         [0.5-0.6)        0.10  0.829      0.888   0.777     0.795   \n",
      "23         [0.5-0.6)        0.20  0.836      0.818   0.855     0.810   \n",
      "24         [0.6-0.7)        0.01  0.662      0.990   0.497     0.580   \n",
      "25         [0.6-0.7)        0.05  0.774      0.922   0.668     0.736   \n",
      "26         [0.6-0.7)        0.10  0.809      0.877   0.750     0.781   \n",
      "27         [0.6-0.7)        0.20  0.816      0.798   0.836     0.791   \n",
      "28         [0.7-0.8)        0.01  0.612      0.995   0.442     0.545   \n",
      "29         [0.7-0.8)        0.05  0.757      0.936   0.635     0.716   \n",
      "30         [0.7-0.8)        0.10  0.807      0.886   0.741     0.783   \n",
      "31         [0.7-0.8)        0.20  0.832      0.814   0.850     0.807   \n",
      "32         [0.8-0.9)        0.01  0.607      0.996   0.436     0.528   \n",
      "33         [0.8-0.9)        0.05  0.748      0.939   0.621     0.696   \n",
      "34         [0.8-0.9)        0.10  0.795      0.898   0.713     0.770   \n",
      "35         [0.8-0.9)        0.20  0.809      0.798   0.820     0.800   \n",
      "36         [0.9-1.0)        0.01  0.648      0.989   0.482     0.562   \n",
      "37         [0.9-1.0)        0.05  0.798      0.958   0.684     0.741   \n",
      "38         [0.9-1.0)        0.10  0.812      0.893   0.744     0.781   \n",
      "39         [0.9-1.0)        0.20  0.825      0.798   0.854     0.804   \n",
      "\n",
      "    num_entries_gt      S  \n",
      "0            12901  6.700  \n",
      "1            12901  4.695  \n",
      "2            12901  3.719  \n",
      "3            12901  3.127  \n",
      "4             4730  6.554  \n",
      "5             4730  4.488  \n",
      "6             4730  3.550  \n",
      "7             4730  2.956  \n",
      "8             3083  6.781  \n",
      "9             3083  4.691  \n",
      "10            3083  3.768  \n",
      "11            3083  3.020  \n",
      "12            2080  6.754  \n",
      "13            2080  4.685  \n",
      "14            2080  3.834  \n",
      "15            2080  3.124  \n",
      "16            1463  6.256  \n",
      "17            1463  4.477  \n",
      "18            1463  3.727  \n",
      "19            1463  3.116  \n",
      "20             993  6.672  \n",
      "21             993  4.787  \n",
      "22             993  3.925  \n",
      "23             993  3.322  \n",
      "24             569  8.004  \n",
      "25             569  5.657  \n",
      "26             569  4.726  \n",
      "27             569  4.144  \n",
      "28             345  8.474  \n",
      "29             345  6.112  \n",
      "30             345  4.989  \n",
      "31             345  4.059  \n",
      "32             202  9.402  \n",
      "33             202  7.231  \n",
      "34             202  5.974  \n",
      "35             202  4.571  \n",
      "36             178  7.358  \n",
      "37             178  5.577  \n",
      "38             178  4.926  \n",
      "39             178  3.662  \n",
      "\n",
      "=== Summary Statistics ===\n",
      "Performance by Disorder Rate Bin (averaged across FDR levels):\n",
      "                      F1  Precision  Recall  Micro_F1\n",
      "disorder_interval                                    \n",
      "[0.0-0.1)          0.826      0.932   0.754     0.778\n",
      "[0.1-0.2)          0.811      0.927   0.735     0.770\n",
      "[0.2-0.3)          0.801      0.925   0.721     0.767\n",
      "[0.3-0.4)          0.790      0.917   0.711     0.752\n",
      "[0.4-0.5)          0.796      0.916   0.719     0.752\n",
      "[0.5-0.6)          0.788      0.909   0.714     0.741\n",
      "[0.6-0.7)          0.765      0.897   0.688     0.722\n",
      "[0.7-0.8)          0.752      0.908   0.667     0.713\n",
      "[0.8-0.9)          0.740      0.908   0.648     0.699\n",
      "[0.9-1.0)          0.771      0.909   0.691     0.722\n",
      "\n",
      "Performance by FDR Level (averaged across disorder bins):\n",
      "               F1  Precision  Recall  Micro_F1\n",
      "target_FDR                                    \n",
      "0.01        0.677      0.991   0.515     0.600\n",
      "0.05        0.796      0.944   0.689     0.751\n",
      "0.10        0.828      0.900   0.767     0.800\n",
      "0.20        0.836      0.824   0.849     0.815\n"
     ]
    }
   ],
   "source": [
    "ontology = 'BPO'\n",
    "ontology_type = 'process'\n",
    "\n",
    "print(\"=== Loading Test Data ===\")\n",
    "test_embeddings_path = r'processed_data_90_30/{0}_test.npy'.format(ontology_type)\n",
    "test_tsv_path = r'processed_data_90_30/{0}_test.tsv'.format(ontology_type)\n",
    "\n",
    "test_embeddings = np.load(test_embeddings_path)\n",
    "test_GO_df, test_embeddings, test_GO_list, test_GO_annotated = process_GO_data(test_tsv_path, test_embeddings)\n",
    "test_GT_entries = test_GO_df['Entry'].tolist()\n",
    "\n",
    "print(f\"Loaded {len(test_GT_entries)} test entries\")\n",
    "\n",
    "with open('{0}_mlb.pkl'.format(ontology_type), 'rb') as f:\n",
    "    mlb = pickle.load(f)\n",
    "\n",
    "print(\"=== Loading Predictions ===\")\n",
    "with open('/Users/harsh/Dropbox/Bridge/pfp_final_aug_3/process_test_predictions_and_FDR_new/bpo/predicted_terms_fdr.pkl', 'rb') as f:\n",
    "    predicted_terms_pkl = pickle.load(f)\n",
    "\n",
    "print(f\"Available FDR levels: {sorted(predicted_terms_pkl.keys())[:10]}...\")  # Show first 10\n",
    "print(f\"Number of entries per FDR level: {len(predicted_terms_pkl[0.01])}\")\n",
    "\n",
    "if len(test_GT_entries) == len(predicted_terms_pkl[0.01]):\n",
    "    print(\"Entry count matches predictions\")\n",
    "else:\n",
    "    print(f\"Warning: {len(test_GT_entries)} entries vs {len(predicted_terms_pkl[0.01])} predictions\")\n",
    "\n",
    "file_path = '{}_test_disorder_rate.tsv'.format(ontology_type)\n",
    "data = pd.read_csv(file_path, sep='\\t')\n",
    "data['disorder_rate_bins'] = pd.cut(data['Disorder Rate'], bins=np.arange(0, 1.1, 0.1), right=False)\n",
    "data_bins_ids_dict = data.groupby('disorder_rate_bins')['Sequence ID'].apply(list).to_dict()\n",
    "\n",
    "print(f\"Disorder rate bins: {list(data_bins_ids_dict.keys())}\")\n",
    "print(f\"Entries per bin: {[(str(k), len(v)) for k, v in data_bins_ids_dict.items()]}\")\n",
    "\n",
    "ia_df = pd.read_csv(r'IA_all.tsv', sep='\\t', header=None)\n",
    "ia_df.columns = ['GO', 'IA']\n",
    "ic_dict = dict(zip(ia_df['GO'], ia_df['IA']))\n",
    "\n",
    "real_annots_dict = {\n",
    "    entry: set(go_terms) \n",
    "    for entry, go_terms in zip(test_GT_entries, test_GO_list)\n",
    "}\n",
    "\n",
    "\n",
    "print(\"=== Starting Analysis ===\")\n",
    "target_fdr_levels = [0.01, 0.05, 0.10, 0.20]\n",
    "results_summary = []\n",
    "\n",
    "for bin_interval, subset_ids in data_bins_ids_dict.items():\n",
    "    print(f\"\\nProcessing bin interval: {bin_interval}\")\n",
    "    print(f\"  Entries in bin: {len(subset_ids)}\")\n",
    "    \n",
    "    filtered_real_annots_dict = {\n",
    "        entry: real_annots_dict[entry]\n",
    "        for entry in subset_ids \n",
    "        if entry in real_annots_dict\n",
    "    }\n",
    "    \n",
    "    print(f\"  Entries with ground truth: {len(filtered_real_annots_dict)}\")\n",
    "    \n",
    "    if not filtered_real_annots_dict:\n",
    "        print(f\"  No ground truth data for interval {bin_interval}, skipping.\")\n",
    "        continue\n",
    "    \n",
    "    for target_fdr in target_fdr_levels:\n",
    "        print(f\"    Evaluating FDR {target_fdr:.0%}...\")\n",
    "        \n",
    "        all_predictions_for_fdr = get_predictions_for_fdr_level(\n",
    "            predicted_terms_pkl, test_GT_entries, target_fdr\n",
    "        )\n",
    "        \n",
    "        pred_set = {\n",
    "            entry: all_predictions_for_fdr[entry] \n",
    "            for entry in subset_ids \n",
    "            if entry in all_predictions_for_fdr\n",
    "        }\n",
    "        \n",
    "        print(f\"      Entries with predictions: {len(pred_set)}\")\n",
    "        \n",
    "        if not pred_set:\n",
    "            print(f\"      No predictions for FDR {target_fdr}, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        (f, p, r, s, ru, mi, f_micro, p_micro, r_micro, \n",
    "         tp_global, fp_global, fn_global) = evaluate_annotations(\n",
    "            ic_dict, filtered_real_annots_dict, pred_set\n",
    "        )\n",
    "        \n",
    "        results_summary.append({\n",
    "            'disorder_interval': f\"[{bin_interval.left:.1f}-{bin_interval.right:.1f})\",\n",
    "            'target_FDR': target_fdr,\n",
    "            'F1': f,\n",
    "            'Precision': p,\n",
    "            'Recall': r,\n",
    "            'Micro_F1': f_micro,\n",
    "            'S': s,\n",
    "            'RU': ru,\n",
    "            'MI': mi,\n",
    "            'TP': tp_global,\n",
    "            'FP': fp_global,\n",
    "            'FN': fn_global,\n",
    "            'num_entries_gt': len(filtered_real_annots_dict),\n",
    "            'num_entries_pred': len(pred_set)\n",
    "        })\n",
    "        \n",
    "        print(f\"      F1: {f:.3f}, Precision: {p:.3f}, Recall: {r:.3f}, Micro F1: {f_micro:.3f}, Smin {s}\")\n",
    "\n",
    "print(\"\\n=== Analysis Complete ===\")\n",
    "results_df_final = pd.DataFrame(results_summary)\n",
    "\n",
    "print(\"\\n--- Summary of Disorder Rate Intervals and Target FDR Metrics ---\")\n",
    "print(results_df_final[['disorder_interval', 'target_FDR', 'F1', 'Precision', 'Recall', 'Micro_F1', 'num_entries_gt', 'S']].round(3))\n",
    "\n",
    "output_file = f'disorder_analysis_results/{ontology_type}_disorder_rate_fdr_analysis.csv'\n",
    "results_df_final.to_csv(output_file, index=False)\n",
    "\n",
    "\n",
    "print(\"\\n=== Summary Statistics ===\")\n",
    "print(\"Performance by Disorder Rate Bin (averaged across FDR levels):\")\n",
    "bin_summary = results_df_final.groupby('disorder_interval')[['F1', 'Precision', 'Recall', 'Micro_F1']].mean()\n",
    "print(bin_summary.round(3))\n",
    "\n",
    "print(\"\\nPerformance by FDR Level (averaged across disorder bins):\")\n",
    "fdr_summary = results_df_final.groupby('target_FDR')[['F1', 'Precision', 'Recall', 'Micro_F1']].mean()\n",
    "print(fdr_summary.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading Test Data ===\n",
      "Loaded 33343 test entries\n",
      "=== Loading Predictions ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NLP/lib/python3.9/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MultiLabelBinarizer from version 1.0.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available FDR levels: [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]...\n",
      "Number of entries per FDR level: 33343\n",
      "Entry count matches predictions\n",
      "Disorder rate bins: [Interval(0.0, 0.1, closed='left'), Interval(0.1, 0.2, closed='left'), Interval(0.2, 0.3, closed='left'), Interval(0.3, 0.4, closed='left'), Interval(0.4, 0.5, closed='left'), Interval(0.5, 0.6, closed='left'), Interval(0.6, 0.7, closed='left'), Interval(0.7, 0.8, closed='left'), Interval(0.8, 0.9, closed='left'), Interval(0.9, 1.0, closed='left')]\n",
      "Entries per bin: [('[0.0, 0.1)', 16904), ('[0.1, 0.2)', 6062), ('[0.2, 0.3)', 3768), ('[0.3, 0.4)', 2558), ('[0.4, 0.5)', 1662), ('[0.5, 0.6)', 1037), ('[0.6, 0.7)', 588), ('[0.7, 0.8)', 347), ('[0.8, 0.9)', 170), ('[0.9, 1.0)', 128)]\n",
      "=== Starting Analysis ===\n",
      "\n",
      "Processing bin interval: [0.0, 0.1)\n",
      "  Entries in bin: 16904\n",
      "  Entries with ground truth: 16904\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 16904\n",
      "      F1: 0.843, Precision: 0.989, Recall: 0.735, Micro F1: 0.855, Smin 3.891447024331223\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 16904\n",
      "      F1: 0.897, Precision: 0.949, Recall: 0.850, Micro F1: 0.905, Smin 2.570548951762685\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 16904\n",
      "      F1: 0.903, Precision: 0.909, Recall: 0.897, Micro F1: 0.909, Smin 1.968741809931351\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 16904\n",
      "      F1: 0.890, Precision: 0.851, Recall: 0.933, Micro F1: 0.896, Smin 2.1308943417768407\n",
      "\n",
      "Processing bin interval: [0.1, 0.2)\n",
      "  Entries in bin: 6062\n",
      "  Entries with ground truth: 6061\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 6061\n",
      "      F1: 0.838, Precision: 0.991, Recall: 0.725, Micro F1: 0.854, Smin 3.969970554060746\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 6061\n",
      "      F1: 0.894, Precision: 0.954, Recall: 0.842, Micro F1: 0.906, Smin 2.678709868058075\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 6061\n",
      "      F1: 0.902, Precision: 0.912, Recall: 0.892, Micro F1: 0.912, Smin 2.068818757084809\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 6061\n",
      "      F1: 0.889, Precision: 0.850, Recall: 0.932, Micro F1: 0.899, Smin 2.1884748318667637\n",
      "\n",
      "Processing bin interval: [0.2, 0.3)\n",
      "  Entries in bin: 3768\n",
      "  Entries with ground truth: 3768\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 3768\n",
      "      F1: 0.831, Precision: 0.989, Recall: 0.717, Micro F1: 0.852, Smin 4.014927730686091\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 3768\n",
      "      F1: 0.890, Precision: 0.950, Recall: 0.837, Micro F1: 0.903, Smin 2.723675713727342\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 3768\n",
      "      F1: 0.897, Precision: 0.908, Recall: 0.887, Micro F1: 0.908, Smin 2.2244508826968823\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 3768\n",
      "      F1: 0.886, Precision: 0.849, Recall: 0.926, Micro F1: 0.895, Smin 2.346284455551094\n",
      "\n",
      "Processing bin interval: [0.3, 0.4)\n",
      "  Entries in bin: 2558\n",
      "  Entries with ground truth: 2558\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 2558\n",
      "      F1: 0.839, Precision: 0.990, Recall: 0.728, Micro F1: 0.859, Smin 3.7936539822982116\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 2558\n",
      "      F1: 0.896, Precision: 0.955, Recall: 0.844, Micro F1: 0.907, Smin 2.5284670255317057\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 2558\n",
      "      F1: 0.900, Precision: 0.911, Recall: 0.890, Micro F1: 0.911, Smin 2.061194537894473\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 2558\n",
      "      F1: 0.888, Precision: 0.852, Recall: 0.927, Micro F1: 0.897, Smin 2.2394475388102895\n",
      "\n",
      "Processing bin interval: [0.4, 0.5)\n",
      "  Entries in bin: 1662\n",
      "  Entries with ground truth: 1662\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 1662\n",
      "      F1: 0.816, Precision: 0.989, Recall: 0.694, Micro F1: 0.847, Smin 4.107441508285085\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 1662\n",
      "      F1: 0.884, Precision: 0.946, Recall: 0.830, Micro F1: 0.902, Smin 2.6956778548081424\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 1662\n",
      "      F1: 0.891, Precision: 0.899, Recall: 0.883, Micro F1: 0.907, Smin 2.188338838908008\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 1662\n",
      "      F1: 0.876, Precision: 0.835, Recall: 0.921, Micro F1: 0.891, Smin 2.3474677257430643\n",
      "\n",
      "Processing bin interval: [0.5, 0.6)\n",
      "  Entries in bin: 1037\n",
      "  Entries with ground truth: 1037\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 1037\n",
      "      F1: 0.806, Precision: 0.990, Recall: 0.680, Micro F1: 0.832, Smin 4.257259749829289\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 1037\n",
      "      F1: 0.880, Precision: 0.952, Recall: 0.818, Micro F1: 0.896, Smin 2.7442111137573173\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 1037\n",
      "      F1: 0.898, Precision: 0.912, Recall: 0.885, Micro F1: 0.910, Smin 2.019330736853896\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 1037\n",
      "      F1: 0.883, Precision: 0.846, Recall: 0.924, Micro F1: 0.896, Smin 2.1388132309966106\n",
      "\n",
      "Processing bin interval: [0.6, 0.7)\n",
      "  Entries in bin: 588\n",
      "  Entries with ground truth: 588\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 588\n",
      "      F1: 0.782, Precision: 0.991, Recall: 0.645, Micro F1: 0.794, Smin 4.394604917330584\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 588\n",
      "      F1: 0.871, Precision: 0.943, Recall: 0.810, Micro F1: 0.877, Smin 2.821168263196695\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 588\n",
      "      F1: 0.882, Precision: 0.888, Recall: 0.876, Micro F1: 0.885, Smin 2.266862456880275\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 588\n",
      "      F1: 0.859, Precision: 0.812, Recall: 0.913, Micro F1: 0.860, Smin 2.61737610606788\n",
      "\n",
      "Processing bin interval: [0.7, 0.8)\n",
      "  Entries in bin: 347\n",
      "  Entries with ground truth: 347\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 347\n",
      "      F1: 0.764, Precision: 0.995, Recall: 0.620, Micro F1: 0.747, Smin 4.485657165576918\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 347\n",
      "      F1: 0.867, Precision: 0.946, Recall: 0.799, Micro F1: 0.853, Smin 2.929590899210208\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 347\n",
      "      F1: 0.872, Precision: 0.884, Recall: 0.861, Micro F1: 0.865, Smin 2.2754667397293704\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 347\n",
      "      F1: 0.841, Precision: 0.787, Recall: 0.902, Micro F1: 0.836, Smin 2.5816380087718755\n",
      "\n",
      "Processing bin interval: [0.8, 0.9)\n",
      "  Entries in bin: 170\n",
      "  Entries with ground truth: 170\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 170\n",
      "      F1: 0.727, Precision: 0.995, Recall: 0.572, Micro F1: 0.719, Smin 4.793524139962617\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 170\n",
      "      F1: 0.833, Precision: 0.917, Recall: 0.763, Micro F1: 0.825, Smin 3.3689794152952803\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 170\n",
      "      F1: 0.828, Precision: 0.826, Recall: 0.831, Micro F1: 0.832, Smin 2.827321054094526\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 170\n",
      "      F1: 0.794, Precision: 0.724, Recall: 0.879, Micro F1: 0.794, Smin 3.3538392399796404\n",
      "\n",
      "Processing bin interval: [0.9, 1.0)\n",
      "  Entries in bin: 128\n",
      "  Entries with ground truth: 128\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 128\n",
      "      F1: 0.705, Precision: 0.990, Recall: 0.547, Micro F1: 0.683, Smin 4.221926464270854\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 128\n",
      "      F1: 0.827, Precision: 0.906, Recall: 0.760, Micro F1: 0.809, Smin 3.108422347258751\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 128\n",
      "      F1: 0.824, Precision: 0.816, Recall: 0.832, Micro F1: 0.815, Smin 2.6700250844804594\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 128\n",
      "      F1: 0.768, Precision: 0.681, Recall: 0.881, Micro F1: 0.758, Smin 3.023863684776254\n",
      "\n",
      "=== Analysis Complete ===\n",
      "\n",
      "--- Summary of Disorder Rate Intervals and Target FDR Metrics ---\n",
      "   disorder_interval  target_FDR     F1  Precision  Recall  Micro_F1  \\\n",
      "0          [0.0-0.1)        0.01  0.843      0.989   0.735     0.855   \n",
      "1          [0.0-0.1)        0.05  0.897      0.949   0.850     0.905   \n",
      "2          [0.0-0.1)        0.10  0.903      0.909   0.897     0.909   \n",
      "3          [0.0-0.1)        0.20  0.890      0.851   0.933     0.896   \n",
      "4          [0.1-0.2)        0.01  0.838      0.991   0.725     0.854   \n",
      "5          [0.1-0.2)        0.05  0.894      0.954   0.842     0.906   \n",
      "6          [0.1-0.2)        0.10  0.902      0.912   0.892     0.912   \n",
      "7          [0.1-0.2)        0.20  0.889      0.850   0.932     0.899   \n",
      "8          [0.2-0.3)        0.01  0.831      0.989   0.717     0.852   \n",
      "9          [0.2-0.3)        0.05  0.890      0.950   0.837     0.903   \n",
      "10         [0.2-0.3)        0.10  0.897      0.908   0.887     0.908   \n",
      "11         [0.2-0.3)        0.20  0.886      0.849   0.926     0.895   \n",
      "12         [0.3-0.4)        0.01  0.839      0.990   0.728     0.859   \n",
      "13         [0.3-0.4)        0.05  0.896      0.955   0.844     0.907   \n",
      "14         [0.3-0.4)        0.10  0.900      0.911   0.890     0.911   \n",
      "15         [0.3-0.4)        0.20  0.888      0.852   0.927     0.897   \n",
      "16         [0.4-0.5)        0.01  0.816      0.989   0.694     0.847   \n",
      "17         [0.4-0.5)        0.05  0.884      0.946   0.830     0.902   \n",
      "18         [0.4-0.5)        0.10  0.891      0.899   0.883     0.907   \n",
      "19         [0.4-0.5)        0.20  0.876      0.835   0.921     0.891   \n",
      "20         [0.5-0.6)        0.01  0.806      0.990   0.680     0.832   \n",
      "21         [0.5-0.6)        0.05  0.880      0.952   0.818     0.896   \n",
      "22         [0.5-0.6)        0.10  0.898      0.912   0.885     0.910   \n",
      "23         [0.5-0.6)        0.20  0.883      0.846   0.924     0.896   \n",
      "24         [0.6-0.7)        0.01  0.782      0.991   0.645     0.794   \n",
      "25         [0.6-0.7)        0.05  0.871      0.943   0.810     0.877   \n",
      "26         [0.6-0.7)        0.10  0.882      0.888   0.876     0.885   \n",
      "27         [0.6-0.7)        0.20  0.859      0.812   0.913     0.860   \n",
      "28         [0.7-0.8)        0.01  0.764      0.995   0.620     0.747   \n",
      "29         [0.7-0.8)        0.05  0.867      0.946   0.799     0.853   \n",
      "30         [0.7-0.8)        0.10  0.872      0.884   0.861     0.865   \n",
      "31         [0.7-0.8)        0.20  0.841      0.787   0.902     0.836   \n",
      "32         [0.8-0.9)        0.01  0.727      0.995   0.572     0.719   \n",
      "33         [0.8-0.9)        0.05  0.833      0.917   0.763     0.825   \n",
      "34         [0.8-0.9)        0.10  0.828      0.826   0.831     0.832   \n",
      "35         [0.8-0.9)        0.20  0.794      0.724   0.879     0.794   \n",
      "36         [0.9-1.0)        0.01  0.705      0.990   0.547     0.683   \n",
      "37         [0.9-1.0)        0.05  0.827      0.906   0.760     0.809   \n",
      "38         [0.9-1.0)        0.10  0.824      0.816   0.832     0.815   \n",
      "39         [0.9-1.0)        0.20  0.768      0.681   0.881     0.758   \n",
      "\n",
      "    num_entries_gt  \n",
      "0            16904  \n",
      "1            16904  \n",
      "2            16904  \n",
      "3            16904  \n",
      "4             6061  \n",
      "5             6061  \n",
      "6             6061  \n",
      "7             6061  \n",
      "8             3768  \n",
      "9             3768  \n",
      "10            3768  \n",
      "11            3768  \n",
      "12            2558  \n",
      "13            2558  \n",
      "14            2558  \n",
      "15            2558  \n",
      "16            1662  \n",
      "17            1662  \n",
      "18            1662  \n",
      "19            1662  \n",
      "20            1037  \n",
      "21            1037  \n",
      "22            1037  \n",
      "23            1037  \n",
      "24             588  \n",
      "25             588  \n",
      "26             588  \n",
      "27             588  \n",
      "28             347  \n",
      "29             347  \n",
      "30             347  \n",
      "31             347  \n",
      "32             170  \n",
      "33             170  \n",
      "34             170  \n",
      "35             170  \n",
      "36             128  \n",
      "37             128  \n",
      "38             128  \n",
      "39             128  \n",
      "\n",
      "=== Summary Statistics ===\n",
      "Performance by Disorder Rate Bin (averaged across FDR levels):\n",
      "                      F1  Precision  Recall  Micro_F1\n",
      "disorder_interval                                    \n",
      "[0.0-0.1)          0.883      0.924   0.854     0.891\n",
      "[0.1-0.2)          0.881      0.927   0.848     0.893\n",
      "[0.2-0.3)          0.876      0.924   0.842     0.889\n",
      "[0.3-0.4)          0.881      0.927   0.847     0.893\n",
      "[0.4-0.5)          0.867      0.917   0.832     0.886\n",
      "[0.5-0.6)          0.867      0.925   0.827     0.883\n",
      "[0.6-0.7)          0.849      0.908   0.811     0.854\n",
      "[0.7-0.8)          0.836      0.903   0.796     0.825\n",
      "[0.8-0.9)          0.796      0.866   0.761     0.792\n",
      "[0.9-1.0)          0.781      0.848   0.755     0.766\n",
      "\n",
      "Performance by FDR Level (averaged across disorder bins):\n",
      "               F1  Precision  Recall  Micro_F1\n",
      "target_FDR                                    \n",
      "0.01        0.795      0.991   0.667     0.804\n",
      "0.05        0.874      0.942   0.815     0.878\n",
      "0.10        0.880      0.886   0.873     0.885\n",
      "0.20        0.857      0.809   0.914     0.862\n"
     ]
    }
   ],
   "source": [
    "ontology = 'MFO'\n",
    "ontology_type = 'function'\n",
    "\n",
    "print(\"=== Loading Test Data ===\")\n",
    "test_embeddings_path = r'processed_data_90_30/{0}_test.npy'.format(ontology_type)\n",
    "test_tsv_path = r'processed_data_90_30/{0}_test.tsv'.format(ontology_type)\n",
    "\n",
    "test_embeddings = np.load(test_embeddings_path)\n",
    "test_GO_df, test_embeddings, test_GO_list, test_GO_annotated = process_GO_data(test_tsv_path, test_embeddings)\n",
    "test_GT_entries = test_GO_df['Entry'].tolist()\n",
    "\n",
    "print(f\"Loaded {len(test_GT_entries)} test entries\")\n",
    "\n",
    "with open('{0}_mlb.pkl'.format(ontology_type), 'rb') as f:\n",
    "    mlb = pickle.load(f)\n",
    "\n",
    "print(\"=== Loading Predictions ===\")\n",
    "with open('/Users/harsh/Dropbox/Bridge/pfp_final_aug_3/process_test_predictions_and_FDR_new/bpo/predicted_terms_fdr.pkl', 'rb') as f:\n",
    "    predicted_terms_pkl = pickle.load(f)\n",
    "\n",
    "print(f\"Available FDR levels: {sorted(predicted_terms_pkl.keys())[:10]}...\")  # Show first 10\n",
    "print(f\"Number of entries per FDR level: {len(predicted_terms_pkl[0.01])}\")\n",
    "\n",
    "if len(test_GT_entries) == len(predicted_terms_pkl[0.01]):\n",
    "    print(\"Entry count matches predictions\")\n",
    "else:\n",
    "    print(f\"Warning: {len(test_GT_entries)} entries vs {len(predicted_terms_pkl[0.01])} predictions\")\n",
    "\n",
    "file_path = '{}_test_disorder_rate.tsv'.format(ontology_type)\n",
    "data = pd.read_csv(file_path, sep='\\t')\n",
    "data['disorder_rate_bins'] = pd.cut(data['Disorder Rate'], bins=np.arange(0, 1.1, 0.1), right=False)\n",
    "data_bins_ids_dict = data.groupby('disorder_rate_bins')['Sequence ID'].apply(list).to_dict()\n",
    "\n",
    "print(f\"Disorder rate bins: {list(data_bins_ids_dict.keys())}\")\n",
    "print(f\"Entries per bin: {[(str(k), len(v)) for k, v in data_bins_ids_dict.items()]}\")\n",
    "\n",
    "ia_df = pd.read_csv(r'IA_all.tsv', sep='\\t', header=None)\n",
    "ia_df.columns = ['GO', 'IA']\n",
    "ic_dict = dict(zip(ia_df['GO'], ia_df['IA']))\n",
    "\n",
    "real_annots_dict = {\n",
    "    entry: set(go_terms) \n",
    "    for entry, go_terms in zip(test_GT_entries, test_GO_list)\n",
    "}\n",
    "\n",
    "\n",
    "print(\"=== Starting Analysis ===\")\n",
    "target_fdr_levels = [0.01, 0.05, 0.10, 0.20]\n",
    "results_summary = []\n",
    "\n",
    "for bin_interval, subset_ids in data_bins_ids_dict.items():\n",
    "    print(f\"\\nProcessing bin interval: {bin_interval}\")\n",
    "    print(f\"  Entries in bin: {len(subset_ids)}\")\n",
    "    \n",
    "    filtered_real_annots_dict = {\n",
    "        entry: real_annots_dict[entry]\n",
    "        for entry in subset_ids \n",
    "        if entry in real_annots_dict\n",
    "    }\n",
    "    \n",
    "    print(f\"  Entries with ground truth: {len(filtered_real_annots_dict)}\")\n",
    "    \n",
    "    if not filtered_real_annots_dict:\n",
    "        print(f\"  No ground truth data for interval {bin_interval}, skipping.\")\n",
    "        continue\n",
    "    \n",
    "    for target_fdr in target_fdr_levels:\n",
    "        print(f\"    Evaluating FDR {target_fdr:.0%}...\")\n",
    "        \n",
    "        all_predictions_for_fdr = get_predictions_for_fdr_level(\n",
    "            predicted_terms_pkl, test_GT_entries, target_fdr\n",
    "        )\n",
    "        \n",
    "        pred_set = {\n",
    "            entry: all_predictions_for_fdr[entry] \n",
    "            for entry in subset_ids \n",
    "            if entry in all_predictions_for_fdr\n",
    "        }\n",
    "        \n",
    "        print(f\"      Entries with predictions: {len(pred_set)}\")\n",
    "        \n",
    "        if not pred_set:\n",
    "            print(f\"      No predictions for FDR {target_fdr}, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        (f, p, r, s, ru, mi, f_micro, p_micro, r_micro, \n",
    "         tp_global, fp_global, fn_global) = evaluate_annotations(\n",
    "            ic_dict, filtered_real_annots_dict, pred_set\n",
    "        )\n",
    "        \n",
    "        results_summary.append({\n",
    "            'disorder_interval': f\"[{bin_interval.left:.1f}-{bin_interval.right:.1f})\",\n",
    "            'target_FDR': target_fdr,\n",
    "            'F1': f,\n",
    "            'Precision': p,\n",
    "            'Recall': r,\n",
    "            'Micro_F1': f_micro,\n",
    "            'S': s,\n",
    "            'RU': ru,\n",
    "            'MI': mi,\n",
    "            'TP': tp_global,\n",
    "            'FP': fp_global,\n",
    "            'FN': fn_global,\n",
    "            'num_entries_gt': len(filtered_real_annots_dict),\n",
    "            'num_entries_pred': len(pred_set)\n",
    "        })\n",
    "        \n",
    "        print(f\"      F1: {f:.3f}, Precision: {p:.3f}, Recall: {r:.3f}, Micro F1: {f_micro:.3f}, Smin {s}\")\n",
    "\n",
    "print(\"\\n=== Analysis Complete ===\")\n",
    "results_df_final = pd.DataFrame(results_summary)\n",
    "\n",
    "print(\"\\n--- Summary of Disorder Rate Intervals and Target FDR Metrics ---\")\n",
    "print(results_df_final[['disorder_interval', 'target_FDR', 'F1', 'Precision', 'Recall', 'Micro_F1', 'num_entries_gt', 'S']].round(3))\n",
    "\n",
    "output_file = f'disorder_analysis_results/{ontology_type}_disorder_rate_fdr_analysis.csv'\n",
    "results_df_final.to_csv(output_file, index=False)\n",
    "\n",
    "\n",
    "print(\"\\n=== Summary Statistics ===\")\n",
    "print(\"Performance by Disorder Rate Bin (averaged across FDR levels):\")\n",
    "bin_summary = results_df_final.groupby('disorder_interval')[['F1', 'Precision', 'Recall', 'Micro_F1']].mean()\n",
    "print(bin_summary.round(3))\n",
    "\n",
    "print(\"\\nPerformance by FDR Level (averaged across disorder bins):\")\n",
    "fdr_summary = results_df_final.groupby('target_FDR')[['F1', 'Precision', 'Recall', 'Micro_F1']].mean()\n",
    "print(fdr_summary.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading Test Data ===\n",
      "Loaded 29679 test entries\n",
      "=== Loading Predictions ===\n",
      "Available FDR levels: [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]...\n",
      "Number of entries per FDR level: 29679\n",
      "Entry count matches predictions\n",
      "Disorder rate bins: [Interval(0.0, 0.1, closed='left'), Interval(0.1, 0.2, closed='left'), Interval(0.2, 0.3, closed='left'), Interval(0.3, 0.4, closed='left'), Interval(0.4, 0.5, closed='left'), Interval(0.5, 0.6, closed='left'), Interval(0.6, 0.7, closed='left'), Interval(0.7, 0.8, closed='left'), Interval(0.8, 0.9, closed='left'), Interval(0.9, 1.0, closed='left')]\n",
      "Entries per bin: [('[0.0, 0.1)', 13038), ('[0.1, 0.2)', 5492), ('[0.2, 0.3)', 3868), ('[0.3, 0.4)', 2646), ('[0.4, 0.5)', 1861), ('[0.5, 0.6)', 1099), ('[0.6, 0.7)', 656), ('[0.7, 0.8)', 407), ('[0.8, 0.9)', 266), ('[0.9, 1.0)', 173)]\n",
      "=== Starting Analysis ===\n",
      "\n",
      "Processing bin interval: [0.0, 0.1)\n",
      "  Entries in bin: 13038\n",
      "  Entries with ground truth: 13038\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 13038\n",
      "      F1: 0.745, Precision: 0.996, Recall: 0.595, Micro F1: 0.611, Smin 2.3747940890063273\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 13038\n",
      "      F1: 0.852, Precision: 0.969, Recall: 0.759, Micro F1: 0.782, Smin 1.5467880004934436\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 13038\n",
      "      F1: 0.880, Precision: 0.943, Recall: 0.825, Micro F1: 0.832, Smin 1.183077985277289\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 13038\n",
      "      F1: 0.893, Precision: 0.894, Recall: 0.892, Micro F1: 0.856, Smin 0.9302821747004971\n",
      "\n",
      "Processing bin interval: [0.1, 0.2)\n",
      "  Entries in bin: 5492\n",
      "  Entries with ground truth: 5491\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 5491\n",
      "      F1: 0.773, Precision: 0.997, Recall: 0.631, Micro F1: 0.640, Smin 2.0946530655157223\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 5491\n",
      "      F1: 0.867, Precision: 0.974, Recall: 0.781, Micro F1: 0.792, Smin 1.3826722135649976\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 5491\n",
      "      F1: 0.891, Precision: 0.946, Recall: 0.841, Micro F1: 0.838, Smin 1.0628965433890671\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 5491\n",
      "      F1: 0.896, Precision: 0.895, Recall: 0.898, Micro F1: 0.854, Smin 0.8630915075795422\n",
      "\n",
      "Processing bin interval: [0.2, 0.3)\n",
      "  Entries in bin: 3868\n",
      "  Entries with ground truth: 3868\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 3868\n",
      "      F1: 0.737, Precision: 0.994, Recall: 0.585, Micro F1: 0.620, Smin 2.343371573762562\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 3868\n",
      "      F1: 0.843, Precision: 0.967, Recall: 0.747, Micro F1: 0.778, Smin 1.576908979919105\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 3868\n",
      "      F1: 0.869, Precision: 0.928, Recall: 0.818, Micro F1: 0.826, Smin 1.194089920781863\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 3868\n",
      "      F1: 0.884, Precision: 0.880, Recall: 0.888, Micro F1: 0.850, Smin 0.9511884361958156\n",
      "\n",
      "Processing bin interval: [0.3, 0.4)\n",
      "  Entries in bin: 2646\n",
      "  Entries with ground truth: 2646\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 2646\n",
      "      F1: 0.724, Precision: 0.993, Recall: 0.570, Micro F1: 0.609, Smin 2.725258760890159\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 2646\n",
      "      F1: 0.838, Precision: 0.966, Recall: 0.739, Micro F1: 0.777, Smin 1.8253176641913005\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 2646\n",
      "      F1: 0.870, Precision: 0.931, Recall: 0.817, Micro F1: 0.830, Smin 1.3650020469259954\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 2646\n",
      "      F1: 0.884, Precision: 0.882, Recall: 0.886, Micro F1: 0.853, Smin 1.0701416203037792\n",
      "\n",
      "Processing bin interval: [0.4, 0.5)\n",
      "  Entries in bin: 1861\n",
      "  Entries with ground truth: 1861\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 1861\n",
      "      F1: 0.704, Precision: 0.992, Recall: 0.545, Micro F1: 0.604, Smin 2.8432025931760463\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 1861\n",
      "      F1: 0.828, Precision: 0.955, Recall: 0.730, Micro F1: 0.778, Smin 1.855907770814363\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 1861\n",
      "      F1: 0.861, Precision: 0.921, Recall: 0.809, Micro F1: 0.831, Smin 1.3859836229833427\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 1861\n",
      "      F1: 0.872, Precision: 0.869, Recall: 0.876, Micro F1: 0.849, Smin 1.1460091764123204\n",
      "\n",
      "Processing bin interval: [0.5, 0.6)\n",
      "  Entries in bin: 1099\n",
      "  Entries with ground truth: 1099\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 1099\n",
      "      F1: 0.678, Precision: 0.995, Recall: 0.514, Micro F1: 0.574, Smin 3.0599788916113027\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 1099\n",
      "      F1: 0.820, Precision: 0.961, Recall: 0.716, Micro F1: 0.773, Smin 1.8945521693446878\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 1099\n",
      "      F1: 0.856, Precision: 0.914, Recall: 0.805, Micro F1: 0.826, Smin 1.4002480430437714\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 1099\n",
      "      F1: 0.866, Precision: 0.853, Recall: 0.880, Micro F1: 0.843, Smin 1.1655118091475403\n",
      "\n",
      "Processing bin interval: [0.6, 0.7)\n",
      "  Entries in bin: 656\n",
      "  Entries with ground truth: 656\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 656\n",
      "      F1: 0.679, Precision: 0.996, Recall: 0.515, Micro F1: 0.590, Smin 3.0350824652074597\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 656\n",
      "      F1: 0.808, Precision: 0.956, Recall: 0.699, Micro F1: 0.762, Smin 2.0192119334375174\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 656\n",
      "      F1: 0.844, Precision: 0.912, Recall: 0.785, Micro F1: 0.812, Smin 1.5338991064629517\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 656\n",
      "      F1: 0.862, Precision: 0.857, Recall: 0.866, Micro F1: 0.837, Smin 1.2504604969972932\n",
      "\n",
      "Processing bin interval: [0.7, 0.8)\n",
      "  Entries in bin: 407\n",
      "  Entries with ground truth: 407\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 407\n",
      "      F1: 0.664, Precision: 0.998, Recall: 0.498, Micro F1: 0.581, Smin 3.27761226957221\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 407\n",
      "      F1: 0.813, Precision: 0.976, Recall: 0.696, Micro F1: 0.770, Smin 2.2189243662296145\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 407\n",
      "      F1: 0.858, Precision: 0.932, Recall: 0.796, Micro F1: 0.830, Smin 1.636196038386429\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 407\n",
      "      F1: 0.879, Precision: 0.878, Recall: 0.880, Micro F1: 0.856, Smin 1.2506186576454568\n",
      "\n",
      "Processing bin interval: [0.8, 0.9)\n",
      "  Entries in bin: 266\n",
      "  Entries with ground truth: 266\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 266\n",
      "      F1: 0.659, Precision: 0.991, Recall: 0.494, Micro F1: 0.583, Smin 3.572168825853979\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 266\n",
      "      F1: 0.789, Precision: 0.959, Recall: 0.670, Micro F1: 0.743, Smin 2.5744340084390775\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 266\n",
      "      F1: 0.848, Precision: 0.921, Recall: 0.786, Micro F1: 0.814, Smin 2.0284433008615443\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 266\n",
      "      F1: 0.869, Precision: 0.875, Recall: 0.864, Micro F1: 0.842, Smin 1.584208501222348\n",
      "\n",
      "Processing bin interval: [0.9, 1.0)\n",
      "  Entries in bin: 173\n",
      "  Entries with ground truth: 173\n",
      "    Evaluating FDR 1%...\n",
      "      Entries with predictions: 173\n",
      "      F1: 0.602, Precision: 0.997, Recall: 0.431, Micro F1: 0.537, Smin 4.199929147190832\n",
      "    Evaluating FDR 5%...\n",
      "      Entries with predictions: 173\n",
      "      F1: 0.754, Precision: 0.935, Recall: 0.631, Micro F1: 0.723, Smin 3.135677518312273\n",
      "    Evaluating FDR 10%...\n",
      "      Entries with predictions: 173\n",
      "      F1: 0.799, Precision: 0.887, Recall: 0.728, Micro F1: 0.780, Smin 2.5821067884095092\n",
      "    Evaluating FDR 20%...\n",
      "      Entries with predictions: 173\n",
      "      F1: 0.817, Precision: 0.818, Recall: 0.815, Micro F1: 0.801, Smin 2.115420344547546\n",
      "\n",
      "=== Analysis Complete ===\n",
      "\n",
      "--- Summary of Disorder Rate Intervals and Target FDR Metrics ---\n",
      "   disorder_interval  target_FDR     F1  Precision  Recall  Micro_F1  \\\n",
      "0          [0.0-0.1)        0.01  0.745      0.996   0.595     0.611   \n",
      "1          [0.0-0.1)        0.05  0.852      0.969   0.759     0.782   \n",
      "2          [0.0-0.1)        0.10  0.880      0.943   0.825     0.832   \n",
      "3          [0.0-0.1)        0.20  0.893      0.894   0.892     0.856   \n",
      "4          [0.1-0.2)        0.01  0.773      0.997   0.631     0.640   \n",
      "5          [0.1-0.2)        0.05  0.867      0.974   0.781     0.792   \n",
      "6          [0.1-0.2)        0.10  0.891      0.946   0.841     0.838   \n",
      "7          [0.1-0.2)        0.20  0.896      0.895   0.898     0.854   \n",
      "8          [0.2-0.3)        0.01  0.737      0.994   0.585     0.620   \n",
      "9          [0.2-0.3)        0.05  0.843      0.967   0.747     0.778   \n",
      "10         [0.2-0.3)        0.10  0.869      0.928   0.818     0.826   \n",
      "11         [0.2-0.3)        0.20  0.884      0.880   0.888     0.850   \n",
      "12         [0.3-0.4)        0.01  0.724      0.993   0.570     0.609   \n",
      "13         [0.3-0.4)        0.05  0.838      0.966   0.739     0.777   \n",
      "14         [0.3-0.4)        0.10  0.870      0.931   0.817     0.830   \n",
      "15         [0.3-0.4)        0.20  0.884      0.882   0.886     0.853   \n",
      "16         [0.4-0.5)        0.01  0.704      0.992   0.545     0.604   \n",
      "17         [0.4-0.5)        0.05  0.828      0.955   0.730     0.778   \n",
      "18         [0.4-0.5)        0.10  0.861      0.921   0.809     0.831   \n",
      "19         [0.4-0.5)        0.20  0.872      0.869   0.876     0.849   \n",
      "20         [0.5-0.6)        0.01  0.678      0.995   0.514     0.574   \n",
      "21         [0.5-0.6)        0.05  0.820      0.961   0.716     0.773   \n",
      "22         [0.5-0.6)        0.10  0.856      0.914   0.805     0.826   \n",
      "23         [0.5-0.6)        0.20  0.866      0.853   0.880     0.843   \n",
      "24         [0.6-0.7)        0.01  0.679      0.996   0.515     0.590   \n",
      "25         [0.6-0.7)        0.05  0.808      0.956   0.699     0.762   \n",
      "26         [0.6-0.7)        0.10  0.844      0.912   0.785     0.812   \n",
      "27         [0.6-0.7)        0.20  0.862      0.857   0.866     0.837   \n",
      "28         [0.7-0.8)        0.01  0.664      0.998   0.498     0.581   \n",
      "29         [0.7-0.8)        0.05  0.813      0.976   0.696     0.770   \n",
      "30         [0.7-0.8)        0.10  0.858      0.932   0.796     0.830   \n",
      "31         [0.7-0.8)        0.20  0.879      0.878   0.880     0.856   \n",
      "32         [0.8-0.9)        0.01  0.659      0.991   0.494     0.583   \n",
      "33         [0.8-0.9)        0.05  0.789      0.959   0.670     0.743   \n",
      "34         [0.8-0.9)        0.10  0.848      0.921   0.786     0.814   \n",
      "35         [0.8-0.9)        0.20  0.869      0.875   0.864     0.842   \n",
      "36         [0.9-1.0)        0.01  0.602      0.997   0.431     0.537   \n",
      "37         [0.9-1.0)        0.05  0.754      0.935   0.631     0.723   \n",
      "38         [0.9-1.0)        0.10  0.799      0.887   0.728     0.780   \n",
      "39         [0.9-1.0)        0.20  0.817      0.818   0.815     0.801   \n",
      "\n",
      "    num_entries_gt  \n",
      "0            13038  \n",
      "1            13038  \n",
      "2            13038  \n",
      "3            13038  \n",
      "4             5491  \n",
      "5             5491  \n",
      "6             5491  \n",
      "7             5491  \n",
      "8             3868  \n",
      "9             3868  \n",
      "10            3868  \n",
      "11            3868  \n",
      "12            2646  \n",
      "13            2646  \n",
      "14            2646  \n",
      "15            2646  \n",
      "16            1861  \n",
      "17            1861  \n",
      "18            1861  \n",
      "19            1861  \n",
      "20            1099  \n",
      "21            1099  \n",
      "22            1099  \n",
      "23            1099  \n",
      "24             656  \n",
      "25             656  \n",
      "26             656  \n",
      "27             656  \n",
      "28             407  \n",
      "29             407  \n",
      "30             407  \n",
      "31             407  \n",
      "32             266  \n",
      "33             266  \n",
      "34             266  \n",
      "35             266  \n",
      "36             173  \n",
      "37             173  \n",
      "38             173  \n",
      "39             173  \n",
      "\n",
      "=== Summary Statistics ===\n",
      "Performance by Disorder Rate Bin (averaged across FDR levels):\n",
      "                      F1  Precision  Recall  Micro_F1\n",
      "disorder_interval                                    \n",
      "[0.0-0.1)          0.842      0.950   0.768     0.770\n",
      "[0.1-0.2)          0.857      0.953   0.788     0.781\n",
      "[0.2-0.3)          0.833      0.942   0.760     0.769\n",
      "[0.3-0.4)          0.829      0.943   0.753     0.767\n",
      "[0.4-0.5)          0.816      0.934   0.740     0.766\n",
      "[0.5-0.6)          0.805      0.931   0.729     0.754\n",
      "[0.6-0.7)          0.798      0.930   0.716     0.750\n",
      "[0.7-0.8)          0.804      0.946   0.717     0.759\n",
      "[0.8-0.9)          0.791      0.937   0.703     0.746\n",
      "[0.9-1.0)          0.743      0.909   0.651     0.711\n",
      "\n",
      "Performance by FDR Level (averaged across disorder bins):\n",
      "               F1  Precision  Recall  Micro_F1\n",
      "target_FDR                                    \n",
      "0.01        0.697      0.995   0.538     0.595\n",
      "0.05        0.821      0.962   0.717     0.768\n",
      "0.10        0.858      0.923   0.801     0.822\n",
      "0.20        0.872      0.870   0.875     0.844\n"
     ]
    }
   ],
   "source": [
    "ontology = 'CCO'\n",
    "ontology_type = 'component'\n",
    "\n",
    "print(\"=== Loading Test Data ===\")\n",
    "test_embeddings_path = r'processed_data_90_30/{0}_test.npy'.format(ontology_type)\n",
    "test_tsv_path = r'processed_data_90_30/{0}_test.tsv'.format(ontology_type)\n",
    "\n",
    "test_embeddings = np.load(test_embeddings_path)\n",
    "test_GO_df, test_embeddings, test_GO_list, test_GO_annotated = process_GO_data(test_tsv_path, test_embeddings)\n",
    "test_GT_entries = test_GO_df['Entry'].tolist()\n",
    "\n",
    "print(f\"Loaded {len(test_GT_entries)} test entries\")\n",
    "\n",
    "with open('{0}_mlb.pkl'.format(ontology_type), 'rb') as f:\n",
    "    mlb = pickle.load(f)\n",
    "\n",
    "print(\"=== Loading Predictions ===\")\n",
    "with open('/Users/harsh/Dropbox/Bridge/pfp_final_aug_3/process_test_predictions_and_FDR_new/bpo/predicted_terms_fdr.pkl', 'rb') as f:\n",
    "    predicted_terms_pkl = pickle.load(f)\n",
    "\n",
    "print(f\"Available FDR levels: {sorted(predicted_terms_pkl.keys())[:10]}...\")  # Show first 10\n",
    "print(f\"Number of entries per FDR level: {len(predicted_terms_pkl[0.01])}\")\n",
    "\n",
    "if len(test_GT_entries) == len(predicted_terms_pkl[0.01]):\n",
    "    print(\"Entry count matches predictions\")\n",
    "else:\n",
    "    print(f\"Warning: {len(test_GT_entries)} entries vs {len(predicted_terms_pkl[0.01])} predictions\")\n",
    "\n",
    "file_path = '{}_test_disorder_rate.tsv'.format(ontology_type)\n",
    "data = pd.read_csv(file_path, sep='\\t')\n",
    "data['disorder_rate_bins'] = pd.cut(data['Disorder Rate'], bins=np.arange(0, 1.1, 0.1), right=False)\n",
    "data_bins_ids_dict = data.groupby('disorder_rate_bins')['Sequence ID'].apply(list).to_dict()\n",
    "\n",
    "print(f\"Disorder rate bins: {list(data_bins_ids_dict.keys())}\")\n",
    "print(f\"Entries per bin: {[(str(k), len(v)) for k, v in data_bins_ids_dict.items()]}\")\n",
    "\n",
    "ia_df = pd.read_csv(r'IA_all.tsv', sep='\\t', header=None)\n",
    "ia_df.columns = ['GO', 'IA']\n",
    "ic_dict = dict(zip(ia_df['GO'], ia_df['IA']))\n",
    "\n",
    "real_annots_dict = {\n",
    "    entry: set(go_terms) \n",
    "    for entry, go_terms in zip(test_GT_entries, test_GO_list)\n",
    "}\n",
    "\n",
    "\n",
    "print(\"=== Starting Analysis ===\")\n",
    "target_fdr_levels = [0.01, 0.05, 0.10, 0.20]\n",
    "results_summary = []\n",
    "\n",
    "for bin_interval, subset_ids in data_bins_ids_dict.items():\n",
    "    print(f\"\\nProcessing bin interval: {bin_interval}\")\n",
    "    print(f\"  Entries in bin: {len(subset_ids)}\")\n",
    "    \n",
    "    filtered_real_annots_dict = {\n",
    "        entry: real_annots_dict[entry]\n",
    "        for entry in subset_ids \n",
    "        if entry in real_annots_dict\n",
    "    }\n",
    "    \n",
    "    print(f\"  Entries with ground truth: {len(filtered_real_annots_dict)}\")\n",
    "    \n",
    "    if not filtered_real_annots_dict:\n",
    "        print(f\"  No ground truth data for interval {bin_interval}, skipping.\")\n",
    "        continue\n",
    "    \n",
    "    for target_fdr in target_fdr_levels:\n",
    "        print(f\"    Evaluating FDR {target_fdr:.0%}...\")\n",
    "        \n",
    "        all_predictions_for_fdr = get_predictions_for_fdr_level(\n",
    "            predicted_terms_pkl, test_GT_entries, target_fdr\n",
    "        )\n",
    "        \n",
    "        pred_set = {\n",
    "            entry: all_predictions_for_fdr[entry] \n",
    "            for entry in subset_ids \n",
    "            if entry in all_predictions_for_fdr\n",
    "        }\n",
    "        \n",
    "        print(f\"      Entries with predictions: {len(pred_set)}\")\n",
    "        \n",
    "        if not pred_set:\n",
    "            print(f\"      No predictions for FDR {target_fdr}, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        (f, p, r, s, ru, mi, f_micro, p_micro, r_micro, \n",
    "         tp_global, fp_global, fn_global) = evaluate_annotations(\n",
    "            ic_dict, filtered_real_annots_dict, pred_set\n",
    "        )\n",
    "        \n",
    "        results_summary.append({\n",
    "            'disorder_interval': f\"[{bin_interval.left:.1f}-{bin_interval.right:.1f})\",\n",
    "            'target_FDR': target_fdr,\n",
    "            'F1': f,\n",
    "            'Precision': p,\n",
    "            'Recall': r,\n",
    "            'Micro_F1': f_micro,\n",
    "            'S': s,\n",
    "            'RU': ru,\n",
    "            'MI': mi,\n",
    "            'TP': tp_global,\n",
    "            'FP': fp_global,\n",
    "            'FN': fn_global,\n",
    "            'num_entries_gt': len(filtered_real_annots_dict),\n",
    "            'num_entries_pred': len(pred_set)\n",
    "        })\n",
    "        \n",
    "        print(f\"      F1: {f:.3f}, Precision: {p:.3f}, Recall: {r:.3f}, Micro F1: {f_micro:.3f}, Smin {s}\")\n",
    "\n",
    "print(\"\\n=== Analysis Complete ===\")\n",
    "results_df_final = pd.DataFrame(results_summary)\n",
    "\n",
    "print(\"\\n--- Summary of Disorder Rate Intervals and Target FDR Metrics ---\")\n",
    "print(results_df_final[['disorder_interval', 'target_FDR', 'F1', 'Precision', 'Recall', 'Micro_F1', 'num_entries_gt', 'S']].round(3))\n",
    "\n",
    "output_file = f'disorder_analysis_results/{ontology_type}_disorder_rate_fdr_analysis.csv'\n",
    "results_df_final.to_csv(output_file, index=False)\n",
    "\n",
    "\n",
    "print(\"\\n=== Summary Statistics ===\")\n",
    "print(\"Performance by Disorder Rate Bin (averaged across FDR levels):\")\n",
    "bin_summary = results_df_final.groupby('disorder_interval')[['F1', 'Precision', 'Recall', 'Micro_F1']].mean()\n",
    "print(bin_summary.round(3))\n",
    "\n",
    "print(\"\\nPerformance by FDR Level (averaged across disorder bins):\")\n",
    "fdr_summary = results_df_final.groupby('target_FDR')[['F1', 'Precision', 'Recall', 'Micro_F1']].mean()\n",
    "print(fdr_summary.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/jqpqz88565l8qdqz4jf3387c0000gn/T/ipykernel_16424/2639892136.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Disorder Level\"] = df[\"disorder_interval\"].apply(map_disorder_level)\n",
      "/var/folders/ky/jqpqz88565l8qdqz4jf3387c0000gn/T/ipykernel_16424/2639892136.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Disorder Level\"] = df[\"disorder_interval\"].apply(map_disorder_level)\n",
      "/var/folders/ky/jqpqz88565l8qdqz4jf3387c0000gn/T/ipykernel_16424/2639892136.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Disorder Level\"] = df[\"disorder_interval\"].apply(map_disorder_level)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subontology</th>\n",
       "      <th>Disorder Level</th>\n",
       "      <th>F_score</th>\n",
       "      <th>S</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>RU</th>\n",
       "      <th>MI</th>\n",
       "      <th>num_proteins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MF</td>\n",
       "      <td>Low Disorder (0.0-0.3)</td>\n",
       "      <td>0.900683</td>\n",
       "      <td>2.087337</td>\n",
       "      <td>0.909572</td>\n",
       "      <td>0.891974</td>\n",
       "      <td>1.892139</td>\n",
       "      <td>0.880420</td>\n",
       "      <td>8911.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MF</td>\n",
       "      <td>Medium Disorder (0.3-0.6)</td>\n",
       "      <td>0.896531</td>\n",
       "      <td>2.089621</td>\n",
       "      <td>0.907324</td>\n",
       "      <td>0.886003</td>\n",
       "      <td>1.924947</td>\n",
       "      <td>0.811932</td>\n",
       "      <td>1752.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MF</td>\n",
       "      <td>High Disorder (0.6+)</td>\n",
       "      <td>0.860905</td>\n",
       "      <td>2.456550</td>\n",
       "      <td>0.865926</td>\n",
       "      <td>0.856013</td>\n",
       "      <td>2.225923</td>\n",
       "      <td>1.034620</td>\n",
       "      <td>368.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BP</td>\n",
       "      <td>Low Disorder (0.0-0.3)</td>\n",
       "      <td>0.852927</td>\n",
       "      <td>3.678927</td>\n",
       "      <td>0.916647</td>\n",
       "      <td>0.797554</td>\n",
       "      <td>3.625800</td>\n",
       "      <td>0.621713</td>\n",
       "      <td>6904.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BP</td>\n",
       "      <td>Medium Disorder (0.3-0.6)</td>\n",
       "      <td>0.832046</td>\n",
       "      <td>3.828675</td>\n",
       "      <td>0.897947</td>\n",
       "      <td>0.775185</td>\n",
       "      <td>3.755125</td>\n",
       "      <td>0.744255</td>\n",
       "      <td>1512.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BP</td>\n",
       "      <td>High Disorder (0.6+)</td>\n",
       "      <td>0.803490</td>\n",
       "      <td>5.229658</td>\n",
       "      <td>0.886958</td>\n",
       "      <td>0.734716</td>\n",
       "      <td>5.158668</td>\n",
       "      <td>0.833654</td>\n",
       "      <td>372.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CC</td>\n",
       "      <td>Low Disorder (0.0-0.3)</td>\n",
       "      <td>0.879935</td>\n",
       "      <td>1.146688</td>\n",
       "      <td>0.938958</td>\n",
       "      <td>0.827910</td>\n",
       "      <td>1.132067</td>\n",
       "      <td>0.182080</td>\n",
       "      <td>7465.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CC</td>\n",
       "      <td>Medium Disorder (0.3-0.6)</td>\n",
       "      <td>0.862568</td>\n",
       "      <td>1.383745</td>\n",
       "      <td>0.921894</td>\n",
       "      <td>0.810417</td>\n",
       "      <td>1.362767</td>\n",
       "      <td>0.237254</td>\n",
       "      <td>1868.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CC</td>\n",
       "      <td>High Disorder (0.6+)</td>\n",
       "      <td>0.850177</td>\n",
       "      <td>1.732846</td>\n",
       "      <td>0.921701</td>\n",
       "      <td>0.788959</td>\n",
       "      <td>1.715029</td>\n",
       "      <td>0.234232</td>\n",
       "      <td>443.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subontology             Disorder Level  ...        MI  num_proteins\n",
       "0          MF     Low Disorder (0.0-0.3)  ...  0.880420   8911.000000\n",
       "1          MF  Medium Disorder (0.3-0.6)  ...  0.811932   1752.333333\n",
       "2          MF       High Disorder (0.6+)  ...  1.034620    368.333333\n",
       "3          BP     Low Disorder (0.0-0.3)  ...  0.621713   6904.666667\n",
       "4          BP  Medium Disorder (0.3-0.6)  ...  0.744255   1512.000000\n",
       "5          BP       High Disorder (0.6+)  ...  0.833654    372.000000\n",
       "6          CC     Low Disorder (0.0-0.3)  ...  0.182080   7465.666667\n",
       "7          CC  Medium Disorder (0.3-0.6)  ...  0.237254   1868.666667\n",
       "8          CC       High Disorder (0.6+)  ...  0.234232    443.000000\n",
       "\n",
       "[9 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "component_df = pd.read_csv(\"disorder_analysis_results/component_disorder_rate_fdr_analysis.csv\")\n",
    "function_df = pd.read_csv(\"disorder_analysis_results/function_disorder_rate_fdr_analysis.csv\")\n",
    "process_df = pd.read_csv(\"disorder_analysis_results/process_disorder_rate_fdr_analysis.csv\")\n",
    "\n",
    "component_fdr10 = component_df[component_df[\"target_FDR\"] == 0.10]\n",
    "function_fdr10 = function_df[function_df[\"target_FDR\"] == 0.10]\n",
    "process_fdr10 = process_df[process_df[\"target_FDR\"] == 0.10]\n",
    "\n",
    "def map_disorder_level(interval):\n",
    "    low = [\"[0.0-0.1)\", \"[0.1-0.2)\", \"[0.2-0.3)\"]\n",
    "    med = [\"[0.3-0.4)\", \"[0.4-0.5)\", \"[0.5-0.6)\"]\n",
    "    high = [\"[0.6-0.7)\", \"[0.7-0.8)\", \"[0.8-0.9)\", \"[0.9-1.0]\"]\n",
    "    if interval in low:\n",
    "        return \"Low Disorder (0.0-0.3)\"\n",
    "    elif interval in med:\n",
    "        return \"Medium Disorder (0.3-0.6)\"\n",
    "    elif interval in high:\n",
    "        return \"High Disorder (0.6+)\"\n",
    "    return None\n",
    "\n",
    "for df in [component_fdr10, function_fdr10, process_fdr10]:\n",
    "    df[\"Disorder Level\"] = df[\"disorder_interval\"].apply(map_disorder_level)\n",
    "\n",
    "def summarize_with_mean(df):\n",
    "    return df.groupby(\"Disorder Level\").agg(\n",
    "        F_score=(\"F1\", \"mean\"),\n",
    "        S=(\"S\", \"mean\"),\n",
    "        Precision=(\"Precision\", \"mean\"),\n",
    "        Recall=(\"Recall\", \"mean\"),\n",
    "        RU=(\"RU\", \"mean\"),\n",
    "        MI=(\"MI\", \"mean\"),\n",
    "        num_proteins=(\"num_entries_gt\", \"mean\")\n",
    "    )\n",
    "\n",
    "component_summary_mean = summarize_with_mean(component_fdr10)\n",
    "function_summary_mean = summarize_with_mean(function_fdr10)\n",
    "process_summary_mean = summarize_with_mean(process_fdr10)\n",
    "\n",
    "rows_mean = []\n",
    "for sub, df in {\"MF\": function_summary_mean, \"BP\": process_summary_mean, \"CC\": component_summary_mean}.items():\n",
    "    for level in [\"Low Disorder (0.0-0.3)\", \"Medium Disorder (0.3-0.6)\", \"High Disorder (0.6+)\"]:\n",
    "        if level in df.index:\n",
    "            row = [sub, level] + df.loc[level].tolist()\n",
    "        else:\n",
    "            row = [sub, level] + [np.nan] * len(df.columns)\n",
    "        rows_mean.append(row)\n",
    "\n",
    "columns_mean = [\"Subontology\", \"Disorder Level\", \"F_score\", \"S\", \"Precision\", \"Recall\", \"RU\", \"MI\", \"num_proteins\"]\n",
    "final_df_mean = pd.DataFrame(rows_mean, columns=columns_mean)\n",
    "\n",
    "final_df_mean\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
